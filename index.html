

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style type="text/css">
      a {
      color: #1772d1;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09227;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Times, sans-serif;
      font-size: 14px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
      }
    </style>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <title>Yanbei Chen</title>

  </head>

  <body>
<!-- introduction + photo -->
	<table width="1000" border="0" align="center" cellpadding="20">
	<tr>
	<td>
	<table width="100%" align="center" border="0" cellpadding="10">
	  	<tr>
	    <td width="60%" valign="middle">
		<p align="center"><font size="6">Yanbei Chen </font></p>
		<p align="justify">
					<br><br>I am a Staff Research Scientist at <a href="https://ai.meta.com/" target="_blank">Meta</a>, working on foundation models. Previously, I was a Senior Scientist at <a href="https://amazon.jobs/content/en/teams/agi" target="_blank">Amazon AGI</a>, where I worked on <a href="https://aws.amazon.com/nova/models/" target="_blank">Amazon Nova foundation models</a>: <a href="https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card" target="_blank">Nova 1</a>, <a href="https://www.amazon.science/publications/amazon-nova-2-multimodal-reasoning-and-generation-models" target="_blank">Nova 2</a>, and <a href="https://www.amazon.science/publications/amazon-nova-multimodal-embeddings-technical-report-and-model-card" target="_blank">Nova Embeddings</a>. I was a Scientist at <a href="https://aws.amazon.com/ai/" target="_blank">Amazon AWS AI Lab</a>, working on <a href="https://aws.amazon.com/rekognition/" target="_blank">Amazon Rekognition models</a>. Prior to my industry experience, I was a postdoc at the University of Tübingen, and received my Ph.D. degree from Queen Mary University of London, advised by Prof. Shaogang Gong. I obtained my M.S. degree from KTH Royal Institute of Technology and my B.S. degree from Zhejiang University.

		</p>

		<p align=center>
		<a href="https://scholar.google.com/citations?user=u66VocEAAAAJ&hl=en" target="_blank"> [Google Scholar]</a>
	  <a href="https://github.com/yanbeic" target="_blank"> [Github]</a>
	  <a href="mailto:yanbeic@gmail.com"> [Email]</a>
	  <a href="https://www.linkedin.com/in/yanbeic/" target="_blank"> [LinkedIn]</a>
	    <br><br>
		</p>
	    </td>

	    <td width="30%" valign="middle" align="center">
	    <img src="img/yanbei.png" alt="Yanbei Chen" style="width: 200px; height: 200px; border-radius: 50%; object-fit: cover;">
		</td>
	</tr>
	</table>

<!-- RELEASED MODELS -->
	<table width="100%" align="center" border="0" cellpadding="10">
	<strong><font size="5" color="#2B547E">Released Models</font></strong>
	<br><br>

		<tr>
		    <td width="100%" valign="top">
			<p>
            <b>Amazon Nova 2: Multimodal Reasoning and Generation Models</b>
            <br>
            <i>Amazon Artificial General Intelligence, December, 2025</i>
            <br>
            <a href="https://www.amazon.science/publications/amazon-nova-2-multimodal-reasoning-and-generation-models" target="_blank">[Tech Report]</a>
            <a href="https://aws.amazon.com/blogs/aws/introducing-amazon-nova-2-lite-a-fast-cost-effective-reasoning-model/" target="_blank">[Blog]</a>
            <br><br>
			</p>
		   	</td>
		</tr>

		<tr>
		    <td width="100%" valign="top">
			<p>
            <b>Amazon Nova 1: The Amazon Nova Family of Models: Technical Report and Model Card</b>
            <br>
            <i>Amazon Artificial General Intelligence, December, 2024</i>
            <br>
            <a href="https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card" target="_blank">[Tech Report]</a>
            <a href="https://www.aboutamazon.com/news/aws/amazon-nova-artificial-intelligence-bedrock-aws" target="_blank">[Blog]</a>
            <br><br>
			</p>
		   	</td>
		</tr>

		<tr>
		    <td width="100%" valign="top">
			<p>
            <b>Amazon Nova Multimodal Embeddings: Technical Report and Model Card</b>
            <br>
            <i>Amazon Artificial General Intelligence, October, 2025 </i>
            <br>
            <a href="https://www.amazon.science/publications/amazon-nova-multimodal-embeddings-technical-report-and-model-card" target="_blank">[Tech Report]</a>
            <a href="https://aws.amazon.com/blogs/aws/amazon-nova-multimodal-embeddings-now-available-in-amazon-bedrock/" target="_blank">[Blog]</a>
            <br><br>
			</p>
		   	</td>
		</tr>
	</table>

<!-- SELECTED PUBLICATIONS -->
	<table width="100%" align="center" border="0" cellpadding="10">
	<strong><font size="5" color="#2B547E">Selected Publications</font></strong>
	<br><br>
	</table>

	<!-- New table for the 3 featured papers -->
	<table width="100%" align="center" border="0" cellpadding="10">
		<!-- CVPR 2024 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/cvpr24.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Hyperbolic Learning with Synthetic Captions for Open-World Detection</b>
            <br>
            Fanjie Kong, <strong>Yanbei Chen</strong>, Jiarui Cai, Davide Modolo <br>
            <i>Conference on Computer Vision and Pattern Recognition, Seattle, USA, June 2024</i>
            <br>
<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kong_Hyperbolic_Learning_with_Synthetic_Captions_for_Open-World_Detection_CVPR_2024_paper.pdf" target="_blank">[PDF]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- CVPR 2023 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/cvpr23.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>ScaleDet: A Scalable Multi-Dataset Object Detector</b>
            <br>
            <strong>Yanbei Chen</strong>, Manchen Wang, Abhay Mittal, Zhenlin Xu, Paolo Favaro, Joseph Tighe, Davide Modolo <br>
            <i>Conference on Computer Vision and Pattern Recognition, Vancouver, CA, June 2023</i>
            <br>
            <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_ScaleDet_A_Scalable_Multi-Dataset_Object_Detector_CVPR_2023_paper.pdf" target="_blank">[PDF]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- TPAMI paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/tpami22.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Semi-Supervised and Unsupervised Deep Visual Learning: A Survey</b>
            <br>
            <strong>Yanbei Chen</strong>, Massimiliano Mancini, Xiatian Zhu, Zeynep Akata <br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</i>
            <br>
            <a href="Doc/TPAMI2022-ChenY.pdf" target="_blank">[PDF]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- CVPRW 2022 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/cvprw22.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Probabilistic Compositional Embeddings for Multimodal Image Retrieval</b>
            <br>
            Andrei Neculai, <strong>Yanbei Chen</strong>, Zeynep Akata <br>
<i>Conference on Computer Vision and Pattern Recognition, MULA Workshop, New Orleans, USA, June 2022</i>
            <br>
            <a href="https://arxiv.org/pdf/2204.05845.pdf" target="_blank">[PDF]</a>
            <a href="https://github.com/andreineculai/MPC" target="_blank">[Code]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- CVPR 2021 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/cvpr21_.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Distilling Audio-Visual Knowledge by Compositional Contrastive Learning</b>
            <br>
            <strong>Yanbei Chen</strong>, Yongqin Xian, Sophia Koepke, Ying Shan, Zeynep Akata <br>
<i>Conference on Computer Vision and Pattern Recognition, Online, June 2021</i>
            <br>
<a href="Doc/CVPR21-ChenY.pdf" target="_blank">[PDF]</a>
            <a href="Doc/CVPR21-ChenY-sup.pdf" target="_blank">[Supplementary]</a>
            <a href="Doc/poster/cvpr21-poster.pdf" target="_blank">[Poster]</a>
            <a href="https://github.com/yanbeic/CCL" target="_blank">[Code]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- CVPR 2020 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/cvpr20_.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Image Search with Text Feedback by Visiolinguistic Attention Learning</b>
            <br>
            <strong>Yanbei Chen</strong>, Shaogang Gong, Loris Bazzani <br>
<i>Conference on Computer Vision and Pattern Recognition, Seattle, USA, June 2020</i>
            <br>
<a href="Doc/CVPR20-ChenY.pdf" target="_blank">[PDF]</a>
            <a href="Doc/CVPR20-ChenY-sup.pdf" target="_blank">[Supplementary]</a>
            <a href="Doc/poster/cvpr20-poster.pdf" target="_blank">[Poster]</a>
            <a href="https://github.com/yanbeic/VAL" target="_blank">[Code]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- AAAI 2020 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/aaai20_.png" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Semi-Supervised Learning under Class Distribution Mismatch</b>
            <br>
            <strong>Yanbei Chen</strong>, Xiatian Zhu, Wei Li, Shaogang Gong <br>
<i>Association for the Advancement of Artificial Intelligence, New York City, USA, February 2020</i>
            <br>
<a href="Doc/AAAI20-ChenY.pdf" target="_blank">[PDF]</a>
            <a href="Doc/AAAI20-ChenY-sup.pdf" target="_blank">[Supplementary]</a>
            <a href="Doc/poster/aaai20-poster.pdf" target="_blank">[Poster]</a>
            <a href="https://github.com/yanbeic/ssl-class-mismatch" target="_blank">[Code]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- ICCV 2019 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/iccv19_.jpg" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Instance-Guided Context Rendering for Cross-Domain Person Re-Identification</b>
            <br>
            <strong>Yanbei Chen</strong>, Xiatian Zhu, Shaogang Gong <br>
<i>International Conference on Computer Vision, Seoul, Korea, October 2019</i>
            <br>
<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Instance-Guided_Context_Rendering_for_Cross-Domain_Person_Re-Identification_ICCV_2019_paper.pdf" target="_blank">[PDF]</a>
            <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Chen_Instance-Guided_Context_Rendering_ICCV_2019_supplemental.pdf" target="_blank">[Supplementary]</a>
            <a href="Doc/poster/iccv19-poster.pdf" target="_blank">[Poster]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- BMVC 2018 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/bmvc18_.jpg" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Deep Association Learning for Unsupervised Video Person Re-identification</b>
            <br>
            <strong>Yanbei Chen</strong>, Xiatian Zhu, Shaogang Gong <br>
<i>British Machine Vision Conference, Newcastle, UK, September 2018</i>
            <br>
<a href="Doc/bmvc18-paper.pdf" target="_blank">[PDF]</a>
            <a href="Doc/poster/bmvc18-poster.pdf" target="_blank">[Poster]</a>
            <a href="https://github.com/yanbeic/Deep-Association-Learning" target="_blank">[Code]</a>
		   	</td>
		</tr>
		<tr><td colspan="1"><br></td></tr>

		<!-- ECCV 2018 paper -->
		<tr>
		    <td width="25%" valign="middle">
		    <img src="img/eccv18_.jpg" width="250" align="middle" style="border-style: none">
		    </td>
		    <td width="75%" valign="middle">
            <b>Semi-Supervised Deep Learning with Memory</b>
            <br>
            <strong>Yanbei Chen</strong>, Xiatian Zhu, Shaogang Gong <br>
<i>European Conference on Computer Vision, Munich, Germany, September 2018</i>
            <br>
<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Yanbei_Chen_Semi-Supervised_Deep_Learning_ECCV_2018_paper.pdf" target="_blank">[PDF]</a>
            <a href="Doc/poster/eccv18-poster.pdf" target="_blank">[Poster]</a>
            <a href="https://github.com/yanbeic/semi-memory" target="_blank">[Code]</a>
		   	</td>
		</tr>
	</table>
	<br><br><br>

<!-- Academic Services -->
	<table width="100%" align="center" border="0" cellpadding="20">
	<strong><font size="5" color="#2B547E">Academic Services</font></strong>
	<tr><td>
	<ul>
	<nobr> <strong> Conference Review Services: </strong> </nobr>
	<li><nobr> CVPR, ICCV, ECCV, NeurIPS, ICLR, BMVC, ACCV, WACV, ICPR, AAAI </nobr></li>
	<!-- <li><nobr> CVPR2020/2021/2022, ICCV2021, NeuRIPS2020/2021, ICLR2022, BMVC2020/2019, ACCV2020, WACV2021, ICPR2021 </nobr></li> -->
	<br>
	<nobr> <strong> Journal Review Services: </strong> </nobr>
	<li><nobr> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </nobr></li>
	<li><nobr> IEEE Transactions on Image Processing (TIP) </nobr></li>
	<li><nobr> IEEE Transactions on Cybernetics </nobr></li>
	<li><nobr> Neurocomputing </nobr></li>
	<li><nobr> Pattern Recognition </nobr></li>
	</ul>
	</td></tr>
	</table>

	</td>
	</tr>
	</table>
	</body>
</html>
